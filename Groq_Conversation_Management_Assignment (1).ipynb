{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conversation Management & Classification using Groq API\n",
        "\n",
        "## Assignment Overview\n",
        "This notebook implements two core tasks using Groq APIs with OpenAI SDK compatibility:\n",
        "1. **Task 1:** Managing Conversation History with Summarization\n",
        "2. **Task 2:** JSON Schema Classification & Information Extraction\n",
        "\n",
        "**Author:** Kunal Sharma\n",
        "**Date:** 25-09-2025\n",
        "---\n"
      ],
      "metadata": {
        "id": "m-5m1YqDWORY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup and Dependencies\n",
        "Installing required libraries and importing necessary modules.\n"
      ],
      "metadata": {
        "id": "6qa-yy5TWRWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install openai -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import re\n",
        "from openai import OpenAI\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0HutEDIWSKp",
        "outputId": "4c40afec-f0ab-49b4-aa1d-93827f6c086f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Groq API Configuration\n",
        "Setting up the Groq API client using OpenAI-compatible SDK.\n"
      ],
      "metadata": {
        "id": "_CjVvLHhWjZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Groq API Configuration\n",
        "GROQ_API_KEY = \"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\"\n",
        "\n",
        "# Initializing Groq client with OpenAI compatibility\n",
        "client = OpenAI(\n",
        "    api_key=GROQ_API_KEY,\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# Available Groq models\n",
        "AVAILABLE_MODELS = {\n",
        "    \"llama\": \"llama-3.1-8b-instant\",\n",
        "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
        "    \"gemma\": \"gemma-7b-it\"\n",
        "}\n",
        "\n",
        "# Using the updated model\n",
        "MODEL = AVAILABLE_MODELS[\"llama\"]\n",
        "\n",
        "# Testing the connection\n",
        "try:\n",
        "    # Simple test call\n",
        "    test_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
        "        max_tokens=10\n",
        "    )\n",
        "    print(\"✅ Groq API connection successful!\")\n",
        "    print(f\"Model being used: {MODEL}\")\n",
        "    print(f\"Test response: {test_response.choices[0].message.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error connecting to Groq API: {str(e)}\")\n",
        "    print(\"Please check your API key and try again.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8j50LPWkCz",
        "outputId": "314816e7-c0ea-4a83-a758-34b7ef189550"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Groq API connection successful!\n",
            "Model being used: llama-3.1-8b-instant\n",
            "Test response: Hello, how are you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Task 1: Managing Conversation History with Summarization\n",
        "\n",
        "### 3.1 Core Classes and Functions\n",
        "Implementing the conversation management system with customizable truncation and periodic summarization.\n"
      ],
      "metadata": {
        "id": "mGznd9-EXbdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    \"\"\"\n",
        "    Manages conversation history with summarization capabilities.\n",
        "    Supports truncation by turns, length, and periodic summarization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: str = MODEL, summarize_every_k: int = 3):\n",
        "        \"\"\"\n",
        "        Initialize the conversation manager.\n",
        "\n",
        "        Args:\n",
        "            model: The Groq model to use\n",
        "            summarize_every_k: Perform summarization after every k conversations\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.conversation_history = []\n",
        "        self.summarized_history = \"\"\n",
        "        self.conversation_count = 0\n",
        "        self.summarize_every_k = summarize_every_k\n",
        "        self.all_summaries = []  # Track all summaries for demonstration\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        \"\"\"Add a message to the conversation history.\"\"\"\n",
        "        self.conversation_history.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "    def get_conversation_for_api(self, max_turns: Optional[int] = None,\n",
        "                                max_chars: Optional[int] = None) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Get conversation history formatted for API calls with truncation options.\n",
        "\n",
        "        Args:\n",
        "            max_turns: Maximum number of conversation turns to include\n",
        "            max_chars: Maximum character length for the conversation\n",
        "        \"\"\"\n",
        "        # Starting with summarized history if exists\n",
        "        messages = []\n",
        "        if self.summarized_history:\n",
        "            messages.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"Previous conversation summary: {self.summarized_history}\"\n",
        "            })\n",
        "\n",
        "        # Getting recent messages\n",
        "        recent_messages = self.conversation_history\n",
        "        if max_turns:\n",
        "            recent_messages = recent_messages[-max_turns:]\n",
        "\n",
        "        # Adding messages with character limit check\n",
        "        current_chars = len(self.summarized_history) if self.summarized_history else 0\n",
        "\n",
        "        for msg in recent_messages:\n",
        "            msg_formatted = {\"role\": msg[\"role\"], \"content\": msg[\"content\"]}\n",
        "            msg_length = len(msg[\"content\"])\n",
        "\n",
        "            if max_chars and current_chars + msg_length > max_chars:\n",
        "                # Truncate the last message if needed\n",
        "                remaining_chars = max_chars - current_chars\n",
        "                if remaining_chars > 50:  # Only add if meaningful content remains\n",
        "                    msg_formatted[\"content\"] = msg[\"content\"][:remaining_chars] + \"...\"\n",
        "                    messages.append(msg_formatted)\n",
        "                break\n",
        "            else:\n",
        "                messages.append(msg_formatted)\n",
        "                current_chars += msg_length\n",
        "\n",
        "        return messages\n",
        "\n",
        "    def summarize_conversation(self) -> str:\n",
        "        \"\"\"Summarize the current conversation history using Groq API.\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"\"\n",
        "\n",
        "        # Prepare conversation for summarization\n",
        "        conversation_text = \"\\n\".join([\n",
        "            f\"{msg['role'].upper()}: {msg['content']}\"\n",
        "            for msg in self.conversation_history\n",
        "        ])\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant that creates concise summaries. Summarize the following conversation, capturing key points, decisions, and important information.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Please summarize this conversation:\\n\\n{conversation_text}\"\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=200,\n",
        "                temperature=0.5\n",
        "            )\n",
        "\n",
        "            summary = response.choices[0].message.content\n",
        "            return summary\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during summarization: {str(e)}\")\n",
        "            return \"Error creating summary\"\n",
        "\n",
        "    def check_and_perform_periodic_summarization(self):\n",
        "        \"\"\"Check if it's time for periodic summarization and perform if needed.\"\"\"\n",
        "        self.conversation_count += 1\n",
        "\n",
        "        if self.conversation_count % self.summarize_every_k == 0:\n",
        "            print(f\"\\n🔄 Performing periodic summarization (every {self.summarize_every_k} conversations)...\")\n",
        "\n",
        "            # Create summary\n",
        "            new_summary = self.summarize_conversation()\n",
        "\n",
        "            # Combine with existing summary if present\n",
        "            if self.summarized_history:\n",
        "                combined_context = f\"Previous summary: {self.summarized_history}\\nNew conversations: {new_summary}\"\n",
        "\n",
        "                # Get a combined summary\n",
        "                try:\n",
        "                    response = client.chat.completions.create(\n",
        "                        model=self.model,\n",
        "                        messages=[\n",
        "                            {\n",
        "                                \"role\": \"system\",\n",
        "                                \"content\": \"Combine these summaries into one concise summary.\"\n",
        "                            },\n",
        "                            {\n",
        "                                \"role\": \"user\",\n",
        "                                \"content\": combined_context\n",
        "                            }\n",
        "                        ],\n",
        "                        max_tokens=250,\n",
        "                        temperature=0.5\n",
        "                    )\n",
        "                    self.summarized_history = response.choices[0].message.content\n",
        "                except:\n",
        "                    self.summarized_history = new_summary\n",
        "            else:\n",
        "                self.summarized_history = new_summary\n",
        "\n",
        "            # Store summary for demonstration\n",
        "            self.all_summaries.append({\n",
        "                \"after_conversation\": self.conversation_count,\n",
        "                \"summary\": self.summarized_history,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "            # Clearing old conversation history after summarization\n",
        "            self.conversation_history = self.conversation_history[-2:]  # Keep last exchange\n",
        "\n",
        "            print(f\"✅ Summary created and stored!\")\n",
        "            print(f\"📝 Summary: {self.summarized_history[:150]}...\")\n",
        "\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def display_status(self):\n",
        "        \"\"\"Display current conversation status.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"📊 CONVERSATION STATUS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Total conversations: {self.conversation_count}\")\n",
        "        print(f\"Messages in current history: {len(self.conversation_history)}\")\n",
        "        print(f\"Summarization scheduled every: {self.summarize_every_k} conversations\")\n",
        "        print(f\"Has summary: {'Yes' if self.summarized_history else 'No'}\")\n",
        "        print(f\"Total summaries created: {len(self.all_summaries)}\")\n",
        "        print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"✅ ConversationManager class created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnGFyRQWW_Ob",
        "outputId": "08d47bc5-83c4-4848-b102-faf38dec842c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ConversationManager class created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Demonstration Functions\n",
        "Functions to demonstrate various truncation options and periodic summarization."
      ],
      "metadata": {
        "id": "z6xiaE-gX-KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def demonstrate_truncation_options():\n",
        "    \"\"\"Demonstrate different truncation options with sample conversations.\"\"\"\n",
        "\n",
        "    print(\"🎯 DEMONSTRATING TRUNCATION OPTIONS\\n\")\n",
        "\n",
        "    # Create a manager with sample conversations\n",
        "    manager = ConversationManager(summarize_every_k=10)  # High k to avoid auto-summarization\n",
        "\n",
        "    # Adding sample conversation\n",
        "    sample_exchanges = [\n",
        "        (\"user\", \"Hi, I'm looking for a good Italian restaurant in downtown.\"),\n",
        "        (\"assistant\", \"I'd be happy to help you find an Italian restaurant downtown! What's your budget range?\"),\n",
        "        (\"user\", \"Something mid-range, around $30-50 per person.\"),\n",
        "        (\"assistant\", \"Great! I recommend 'Bella Vista' on Main Street. They have excellent pasta and a cozy atmosphere.\"),\n",
        "        (\"user\", \"Do they have vegetarian options?\"),\n",
        "        (\"assistant\", \"Yes, Bella Vista has several vegetarian options including eggplant parmigiana and various pasta dishes.\"),\n",
        "        (\"user\", \"Perfect! What are their hours?\"),\n",
        "        (\"assistant\", \"They're open Tuesday-Sunday, 11:30 AM to 10 PM. Closed on Mondays.\"),\n",
        "        (\"user\", \"Can I make a reservation online?\"),\n",
        "        (\"assistant\", \"Yes, you can make reservations through their website or by calling them directly.\")\n",
        "    ]\n",
        "\n",
        "    # Adding messages to manager\n",
        "    for role, content in sample_exchanges:\n",
        "        manager.add_message(role, content)\n",
        "\n",
        "    print(\"📝 Original conversation has\", len(sample_exchanges), \"messages\\n\")\n",
        "\n",
        "    # Demonstrate truncation by turns\n",
        "    print(\"1️⃣ TRUNCATION BY NUMBER OF TURNS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for max_turns in [2, 4, 6]:\n",
        "        truncated = manager.get_conversation_for_api(max_turns=max_turns)\n",
        "        print(f\"\\n✂️  Last {max_turns} turns:\")\n",
        "        print(f\"   Messages included: {len(truncated)}\")\n",
        "        print(f\"   First message: {truncated[0]['content'][:60]}...\")\n",
        "        print(f\"   Last message: {truncated[-1]['content'][:60]}...\")\n",
        "\n",
        "    # Demonstrate truncation by character length\n",
        "    print(\"\\n\\n2️⃣ TRUNCATION BY CHARACTER LENGTH:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for max_chars in [200, 400, 600]:\n",
        "        truncated = manager.get_conversation_for_api(max_chars=max_chars)\n",
        "        total_chars = sum(len(msg['content']) for msg in truncated)\n",
        "        print(f\"\\n✂️  Max {max_chars} characters:\")\n",
        "        print(f\"   Messages included: {len(truncated)}\")\n",
        "        print(f\"   Total characters: {total_chars}\")\n",
        "        print(f\"   Last message: {truncated[-1]['content'][:60]}...\")\n",
        "\n",
        "    # Demonstrate combined truncation\n",
        "    print(\"\\n\\n3️⃣ COMBINED TRUNCATION (turns + chars):\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    truncated = manager.get_conversation_for_api(max_turns=4, max_chars=300)\n",
        "    total_chars = sum(len(msg['content']) for msg in truncated)\n",
        "    print(f\"\\n✂️  Max 4 turns AND 300 characters:\")\n",
        "    print(f\"   Messages included: {len(truncated)}\")\n",
        "    print(f\"   Total characters: {total_chars}\")\n",
        "\n",
        "    return manager\n",
        "\n",
        "\n",
        "def demonstrate_periodic_summarization():\n",
        "    \"\"\"Demonstrate periodic summarization after every k conversations.\"\"\"\n",
        "\n",
        "    print(\"\\n\\n🔄 DEMONSTRATING PERIODIC SUMMARIZATION\\n\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Creating manager with summarization every 3 conversations\n",
        "    manager = ConversationManager(summarize_every_k=3)\n",
        "\n",
        "    # Sample conversation scenarios\n",
        "    conversation_scenarios = [\n",
        "        # Conversation 1: Restaurant inquiry\n",
        "        [\n",
        "            (\"user\", \"I need a restaurant recommendation for a business dinner.\"),\n",
        "            (\"assistant\", \"I'd recommend The Executive Lounge for business dinners. It has private dining areas and excellent service.\"),\n",
        "            (\"user\", \"What's the dress code?\"),\n",
        "            (\"assistant\", \"Business formal is required. Jackets for men, and business attire for all guests.\")\n",
        "        ],\n",
        "\n",
        "        # Conversation 2: Travel planning\n",
        "        [\n",
        "            (\"user\", \"I'm planning a trip to Paris next month. Any advice?\"),\n",
        "            (\"assistant\", \"Paris is wonderful! I recommend visiting the Eiffel Tower early morning to avoid crowds.\"),\n",
        "            (\"user\", \"What about accommodation?\"),\n",
        "            (\"assistant\", \"The Marais district is great for tourists - central location and many boutique hotels.\")\n",
        "        ],\n",
        "\n",
        "        # Conversation 3: Tech support (triggers summarization)\n",
        "        [\n",
        "            (\"user\", \"My laptop keeps freezing. What should I do?\"),\n",
        "            (\"assistant\", \"First, try restarting in safe mode. Also check for any pending system updates.\"),\n",
        "            (\"user\", \"It's still slow after updates.\"),\n",
        "            (\"assistant\", \"You might need to check for malware or consider increasing your RAM.\")\n",
        "        ],\n",
        "\n",
        "        # Conversation 4: Fitness advice\n",
        "        [\n",
        "            (\"user\", \"I want to start working out. Any beginner tips?\"),\n",
        "            (\"assistant\", \"Start with 3 days a week, focusing on full-body exercises. Don't forget to warm up!\"),\n",
        "            (\"user\", \"What about diet?\"),\n",
        "            (\"assistant\", \"Focus on protein intake and stay hydrated. Avoid drastic diet changes initially.\")\n",
        "        ],\n",
        "\n",
        "        # Conversation 5: Book recommendations\n",
        "        [\n",
        "            (\"user\", \"Can you recommend some sci-fi books?\"),\n",
        "            (\"assistant\", \"Try 'Dune' by Frank Herbert or 'The Expanse' series by James S.A. Corey.\"),\n",
        "            (\"user\", \"Something more recent?\"),\n",
        "            (\"assistant\", \"Andy Weir's 'Project Hail Mary' is excellent and was published in 2021.\")\n",
        "        ],\n",
        "\n",
        "        # Conversation 6: Cooking help (triggers summarization)\n",
        "        [\n",
        "            (\"user\", \"How do I make a perfect omelette?\"),\n",
        "            (\"assistant\", \"Use medium-low heat, beat eggs thoroughly, and add fillings when eggs are slightly wet on top.\"),\n",
        "            (\"user\", \"My omelettes always break when I flip them.\"),\n",
        "            (\"assistant\", \"Try the fold method instead of flipping - just fold in half when bottom is set.\")\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    # Processing each conversation\n",
        "    for i, conversation in enumerate(conversation_scenarios, 1):\n",
        "        print(f\"\\n💬 CONVERSATION {i}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Add messages from this conversation\n",
        "        for role, content in conversation:\n",
        "            manager.add_message(role, content)\n",
        "            print(f\"{role.upper()}: {content}\")\n",
        "\n",
        "        # Check for periodic summarization\n",
        "        summarized = manager.check_and_perform_periodic_summarization()\n",
        "\n",
        "        if not summarized:\n",
        "            print(f\"\\n📌 No summarization yet. Waiting for conversation {manager.summarize_every_k}\")\n",
        "\n",
        "    # Display final status\n",
        "    manager.display_status()\n",
        "\n",
        "    # Show all summaries created\n",
        "    print(\"\\n📚 ALL SUMMARIES CREATED:\")\n",
        "    print(\"=\"*60)\n",
        "    for i, summary_info in enumerate(manager.all_summaries, 1):\n",
        "        print(f\"\\nSummary #{i} (After conversation {summary_info['after_conversation']}):\")\n",
        "        print(f\"Created at: {summary_info['timestamp']}\")\n",
        "        print(f\"Content: {summary_info['summary']}\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "    return manager\n",
        "\n",
        "\n",
        "# Execute demonstrations\n",
        "print(\"Ready to run demonstrations! Use the functions below.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqyFnOQQX5a8",
        "outputId": "8be3741d-5993-482a-aa16-858c9021b352"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to run demonstrations! Use the functions below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Task 1 Demonstrations\n",
        "Running demonstrations to show truncation options and periodic summarization functionality.\n"
      ],
      "metadata": {
        "id": "3rz4ggPuYQhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running Demonstration 1: Truncation Options\n",
        "print(\"DEMONSTRATION 1: TRUNCATION OPTIONS\")\n",
        "print(\"=\" * 80)\n",
        "manager1 = demonstrate_truncation_options()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFzV2o7GYScC",
        "outputId": "f4968c64-14bb-47c1-885e-854a9ce9d632"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEMONSTRATION 1: TRUNCATION OPTIONS\n",
            "================================================================================\n",
            "🎯 DEMONSTRATING TRUNCATION OPTIONS\n",
            "\n",
            "📝 Original conversation has 10 messages\n",
            "\n",
            "1️⃣ TRUNCATION BY NUMBER OF TURNS:\n",
            "----------------------------------------\n",
            "\n",
            "✂️  Last 2 turns:\n",
            "   Messages included: 2\n",
            "   First message: Can I make a reservation online?...\n",
            "   Last message: Yes, you can make reservations through their website or by c...\n",
            "\n",
            "✂️  Last 4 turns:\n",
            "   Messages included: 4\n",
            "   First message: Perfect! What are their hours?...\n",
            "   Last message: Yes, you can make reservations through their website or by c...\n",
            "\n",
            "✂️  Last 6 turns:\n",
            "   Messages included: 6\n",
            "   First message: Do they have vegetarian options?...\n",
            "   Last message: Yes, you can make reservations through their website or by c...\n",
            "\n",
            "\n",
            "2️⃣ TRUNCATION BY CHARACTER LENGTH:\n",
            "----------------------------------------\n",
            "\n",
            "✂️  Max 200 characters:\n",
            "   Messages included: 3\n",
            "   Total characters: 191\n",
            "   Last message: Something mid-range, around $30-50 per person....\n",
            "\n",
            "✂️  Max 400 characters:\n",
            "   Messages included: 6\n",
            "   Total characters: 403\n",
            "   Last message: Yes, Bella Vista has several vegetarian options including eg...\n",
            "\n",
            "✂️  Max 600 characters:\n",
            "   Messages included: 9\n",
            "   Total characters: 551\n",
            "   Last message: Can I make a reservation online?...\n",
            "\n",
            "\n",
            "3️⃣ COMBINED TRUNCATION (turns + chars):\n",
            "----------------------------------------\n",
            "\n",
            "✂️  Max 4 turns AND 300 characters:\n",
            "   Messages included: 4\n",
            "   Total characters: 209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running Demonstration 2: Periodic Summarization\n",
        "print(\"\\n\\nDEMONSTRATION 2: PERIODIC SUMMARIZATION\")\n",
        "print(\"=\" * 80)\n",
        "manager2 = demonstrate_periodic_summarization()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikY9vq-DX6FT",
        "outputId": "0752194a-f2c8-456e-9d15-4853373c7057"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "DEMONSTRATION 2: PERIODIC SUMMARIZATION\n",
            "================================================================================\n",
            "\n",
            "\n",
            "🔄 DEMONSTRATING PERIODIC SUMMARIZATION\n",
            "\n",
            "============================================================\n",
            "\n",
            "💬 CONVERSATION 1\n",
            "----------------------------------------\n",
            "USER: I need a restaurant recommendation for a business dinner.\n",
            "ASSISTANT: I'd recommend The Executive Lounge for business dinners. It has private dining areas and excellent service.\n",
            "USER: What's the dress code?\n",
            "ASSISTANT: Business formal is required. Jackets for men, and business attire for all guests.\n",
            "\n",
            "📌 No summarization yet. Waiting for conversation 3\n",
            "\n",
            "💬 CONVERSATION 2\n",
            "----------------------------------------\n",
            "USER: I'm planning a trip to Paris next month. Any advice?\n",
            "ASSISTANT: Paris is wonderful! I recommend visiting the Eiffel Tower early morning to avoid crowds.\n",
            "USER: What about accommodation?\n",
            "ASSISTANT: The Marais district is great for tourists - central location and many boutique hotels.\n",
            "\n",
            "📌 No summarization yet. Waiting for conversation 3\n",
            "\n",
            "💬 CONVERSATION 3\n",
            "----------------------------------------\n",
            "USER: My laptop keeps freezing. What should I do?\n",
            "ASSISTANT: First, try restarting in safe mode. Also check for any pending system updates.\n",
            "USER: It's still slow after updates.\n",
            "ASSISTANT: You might need to check for malware or consider increasing your RAM.\n",
            "\n",
            "🔄 Performing periodic summarization (every 3 conversations)...\n",
            "✅ Summary created and stored!\n",
            "📝 Summary: Here's a summary of the conversation:\n",
            "\n",
            "- The Assistant recommended **The Executive Lounge** for a business dinner, citing private dining areas and exc...\n",
            "\n",
            "💬 CONVERSATION 4\n",
            "----------------------------------------\n",
            "USER: I want to start working out. Any beginner tips?\n",
            "ASSISTANT: Start with 3 days a week, focusing on full-body exercises. Don't forget to warm up!\n",
            "USER: What about diet?\n",
            "ASSISTANT: Focus on protein intake and stay hydrated. Avoid drastic diet changes initially.\n",
            "\n",
            "📌 No summarization yet. Waiting for conversation 3\n",
            "\n",
            "💬 CONVERSATION 5\n",
            "----------------------------------------\n",
            "USER: Can you recommend some sci-fi books?\n",
            "ASSISTANT: Try 'Dune' by Frank Herbert or 'The Expanse' series by James S.A. Corey.\n",
            "USER: Something more recent?\n",
            "ASSISTANT: Andy Weir's 'Project Hail Mary' is excellent and was published in 2021.\n",
            "\n",
            "📌 No summarization yet. Waiting for conversation 3\n",
            "\n",
            "💬 CONVERSATION 6\n",
            "----------------------------------------\n",
            "USER: How do I make a perfect omelette?\n",
            "ASSISTANT: Use medium-low heat, beat eggs thoroughly, and add fillings when eggs are slightly wet on top.\n",
            "USER: My omelettes always break when I flip them.\n",
            "ASSISTANT: Try the fold method instead of flipping - just fold in half when bottom is set.\n",
            "\n",
            "🔄 Performing periodic summarization (every 3 conversations)...\n",
            "✅ Summary created and stored!\n",
            "📝 Summary: Here's a concise summary of the conversation:\n",
            "\n",
            "The Assistant provided various recommendations and solutions:\n",
            "\n",
            "- For a business dinner, **The Executive...\n",
            "\n",
            "==================================================\n",
            "📊 CONVERSATION STATUS\n",
            "==================================================\n",
            "Total conversations: 6\n",
            "Messages in current history: 2\n",
            "Summarization scheduled every: 3 conversations\n",
            "Has summary: Yes\n",
            "Total summaries created: 2\n",
            "==================================================\n",
            "\n",
            "\n",
            "📚 ALL SUMMARIES CREATED:\n",
            "============================================================\n",
            "\n",
            "Summary #1 (After conversation 3):\n",
            "Created at: 2025-09-25T10:42:06.637992\n",
            "Content: Here's a summary of the conversation:\n",
            "\n",
            "- The Assistant recommended **The Executive Lounge** for a business dinner, citing private dining areas and excellent service. The dress code is business formal, with jackets required for men.\n",
            "\n",
            "- For a trip to Paris, the Assistant suggested visiting the Eiffel Tower early morning to avoid crowds and staying in the **Marais district**, which offers a central location and many boutique hotels.\n",
            "\n",
            "- Regarding a laptop freezing issue, the Assistant recommended trying the following:\n",
            "  1. Restarting in safe mode\n",
            "  2. Checking for pending system updates\n",
            "  3. If the issue persists, checking for malware\n",
            "  4. Considering increasing the RAM (if necessary)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Summary #2 (After conversation 6):\n",
            "Created at: 2025-09-25T10:42:07.520546\n",
            "Content: Here's a concise summary of the conversation:\n",
            "\n",
            "The Assistant provided various recommendations and solutions:\n",
            "\n",
            "- For a business dinner, **The Executive Lounge** was suggested, with a business formal dress code and excellent service.\n",
            "- For a trip to Paris, the Assistant recommended visiting the Eiffel Tower early morning and staying in the **Marais district**.\n",
            "- Regarding laptop issues, solutions included restarting in safe mode, checking for pending system updates, checking for malware, and increasing RAM.\n",
            "- For a user experiencing slow performance after updates, the Assistant suggested checking for malware and increasing RAM as potential solutions.\n",
            "- For a user starting a workout routine, the Assistant recommended starting with 3 days a week of full-body exercises, warming up, focusing on protein intake, and staying hydrated.\n",
            "- For sci-fi book recommendations, the Assistant suggested 'Dune' by Frank Herbert, 'The Expanse' series by James S.A. Corey, and 'Project Hail Mary' by Andy Weir.\n",
            "- For making a perfect omelette, the Assistant provided tips including using medium-low heat, beating eggs thoroughly, adding fillings when eggs are slightly wet on top, and using the fold method instead of flipping.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Task 2: JSON Schema Classification & Information Extraction\n",
        "\n",
        "### 4.1 JSON Schema Definition and Function Calling Setup\n",
        "Implementing structured data extraction using Groq's function calling capabilities.\n"
      ],
      "metadata": {
        "id": "m9LuBb6JY1A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the JSON schema for information extraction\n",
        "information_schema = {\n",
        "    \"name\": \"extract_user_information\",\n",
        "    \"description\": \"Extract user information from a conversation\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's full name\"\n",
        "            },\n",
        "            \"email\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's email address\"\n",
        "            },\n",
        "            \"phone\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's phone number\"\n",
        "            },\n",
        "            \"location\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"city\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The user's city\"\n",
        "                    },\n",
        "                    \"state\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The user's state or province\"\n",
        "                    },\n",
        "                    \"country\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The user's country\"\n",
        "                    }\n",
        "                },\n",
        "                \"description\": \"The user's location details\"\n",
        "            },\n",
        "            \"age\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"The user's age\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": []\n",
        "    }\n",
        "}\n",
        "\n",
        "class InformationExtractor:\n",
        "    \"\"\"Extract structured information from conversations using Groq function calling.\"\"\"\n",
        "\n",
        "    def __init__(self, model: str = MODEL):\n",
        "        self.model = model\n",
        "        self.schema = information_schema\n",
        "\n",
        "    def extract_information(self, conversation: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extract information from a conversation using function calling.\n",
        "\n",
        "        Args:\n",
        "            conversation: The conversation text to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing extracted information\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant that extracts user information from conversations. Extract only explicitly stated information.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Extract user information from this conversation:\\n\\n{conversation}\"\n",
        "                    }\n",
        "                ],\n",
        "                tools=[{\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": self.schema\n",
        "                }],\n",
        "                tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_user_information\"}},\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the function call result\n",
        "            if response.choices[0].message.tool_calls:\n",
        "                tool_call = response.choices[0].message.tool_calls[0]\n",
        "                extracted_data = json.loads(tool_call.function.arguments)\n",
        "                return extracted_data\n",
        "            else:\n",
        "                return {}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during extraction: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def validate_against_schema(self, data: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Validate extracted data against the schema.\n",
        "\n",
        "        Args:\n",
        "            data: The extracted data dictionary\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, list_of_errors)\n",
        "        \"\"\"\n",
        "        errors = []\n",
        "\n",
        "        # Check data types\n",
        "        if 'name' in data and not isinstance(data['name'], str):\n",
        "            errors.append(\"Name must be a string\")\n",
        "\n",
        "        if 'email' in data:\n",
        "            if not isinstance(data['email'], str):\n",
        "                errors.append(\"Email must be a string\")\n",
        "            elif '@' not in data['email']:\n",
        "                errors.append(\"Email format appears invalid\")\n",
        "\n",
        "        if 'phone' in data and not isinstance(data['phone'], str):\n",
        "            errors.append(\"Phone must be a string\")\n",
        "\n",
        "        if 'age' in data:\n",
        "            if not isinstance(data['age'], int):\n",
        "                errors.append(\"Age must be an integer\")\n",
        "            elif data['age'] < 0 or data['age'] > 150:\n",
        "                errors.append(\"Age value seems unrealistic\")\n",
        "\n",
        "        if 'location' in data:\n",
        "            if not isinstance(data['location'], dict):\n",
        "                errors.append(\"Location must be an object\")\n",
        "            else:\n",
        "                loc = data['location']\n",
        "                for field in ['city', 'state', 'country']:\n",
        "                    if field in loc and not isinstance(loc[field], str):\n",
        "                        errors.append(f\"Location {field} must be a string\")\n",
        "\n",
        "        is_valid = len(errors) == 0\n",
        "        return is_valid, errors\n",
        "\n",
        "    def display_extraction_result(self, conversation: str, extracted_data: Dict[str, Any],\n",
        "                                validation_result: Tuple[bool, List[str]]):\n",
        "        \"\"\"Display the extraction results in a formatted way.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"📝 CONVERSATION:\")\n",
        "        print(\"-\"*60)\n",
        "        print(conversation)\n",
        "\n",
        "        print(\"\\n🔍 EXTRACTED INFORMATION:\")\n",
        "        print(\"-\"*60)\n",
        "        if extracted_data:\n",
        "            print(json.dumps(extracted_data, indent=2))\n",
        "        else:\n",
        "            print(\"No information extracted\")\n",
        "\n",
        "        print(\"\\n✅ VALIDATION RESULT:\")\n",
        "        print(\"-\"*60)\n",
        "        is_valid, errors = validation_result\n",
        "        if is_valid:\n",
        "            print(\"✓ Data is valid according to schema\")\n",
        "        else:\n",
        "            print(\"✗ Validation errors found:\")\n",
        "            for error in errors:\n",
        "                print(f\"  - {error}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "print(\"✅ InformationExtractor class and schema created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-u0CcTYoCx",
        "outputId": "ca7f0a93-9c7d-4795-911b-75543d2064a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ InformationExtractor class and schema created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Sample Conversations for Information Extraction\n",
        "Testing the extraction system with diverse conversation examples.\n"
      ],
      "metadata": {
        "id": "U1HgJJQMZBku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample conversations for testing\n",
        "sample_conversations = [\n",
        "    # Conversation 1: Complete information\n",
        "    \"\"\"\n",
        "    Customer: Hi, I'd like to create an account.\n",
        "    Support: Sure! I'd be happy to help you create an account. May I have your full name?\n",
        "    Customer: Yes, my name is John Michael Smith.\n",
        "    Support: Thank you, Mr. Smith. And what email address would you like to use?\n",
        "    Customer: Please use john.smith@email.com\n",
        "    Support: Perfect. Can I also get a phone number for account security?\n",
        "    Customer: Sure, it's +1-555-123-4567\n",
        "    Support: Great! And where are you located?\n",
        "    Customer: I'm in San Francisco, California, United States.\n",
        "    Support: Excellent. One last thing - may I ask your age for our demographics?\n",
        "    Customer: I'm 28 years old.\n",
        "    Support: Thank you! Your account has been created successfully.\n",
        "    \"\"\",\n",
        "\n",
        "    # Conversation 2: Partial information\n",
        "    \"\"\"\n",
        "    User: Hello, I'm interested in your services.\n",
        "    Agent: Welcome! I'd be glad to help. What's your name?\n",
        "    User: I'm Sarah Johnson.\n",
        "    Agent: Nice to meet you, Sarah. How can I reach you?\n",
        "    User: You can email me at sarah.j@gmail.com\n",
        "    Agent: Thanks! Where are you based?\n",
        "    User: I'm in Toronto, Canada.\n",
        "    Agent: Great! Do you mind sharing your age group for our records?\n",
        "    User: I'd prefer not to share that information.\n",
        "    Agent: No problem at all! Let me show you our services.\n",
        "    \"\"\",\n",
        "\n",
        "    # Conversation 3: Information scattered throughout casual conversation\n",
        "    \"\"\"\n",
        "    Customer: Hi there! I just moved to Austin, Texas from New York.\n",
        "    Sales: Welcome to Austin! How are you finding it so far?\n",
        "    Customer: It's great! Much warmer than NYC. By the way, I'm David Lee.\n",
        "    Sales: Nice to meet you, David! What brings you to our store today?\n",
        "    Customer: I need to update my contact information. I'm 35 now and figured it's time to get organized.\n",
        "    Sales: Absolutely! What's the best way to reach you?\n",
        "    Customer: My phone is 512-789-0123. That's the best way.\n",
        "    Sales: Got it. Do you have an email as well?\n",
        "    Customer: Oh yes, david.lee.35@hotmail.com - I know, showing my age with Hotmail!\n",
        "    Sales: Haha, no judgment here! Let me update your information.\n",
        "    Customer: Actually, I should mention I'm originally from South Korea, moved to the US five years ago.\n",
        "    Sales: Thanks for sharing! Is Austin, Texas your permanent address now?\n",
        "    Customer: Yes, Austin, Texas, USA is home now!\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# Creating the extractor\n",
        "extractor = InformationExtractor()\n",
        "\n",
        "# Processing each conversation\n",
        "print(\"🎯 TESTING INFORMATION EXTRACTION ON SAMPLE CONVERSATIONS\\n\")\n",
        "\n",
        "for i, conversation in enumerate(sample_conversations, 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📋 TEST CASE {i}\")\n",
        "    print('='*80)\n",
        "\n",
        "    # Extracting information\n",
        "    extracted_data = extractor.extract_information(conversation)\n",
        "\n",
        "    # Validating the extracted data\n",
        "    validation_result = extractor.validate_against_schema(extracted_data)\n",
        "\n",
        "    # Displaying results\n",
        "    extractor.display_extraction_result(conversation, extracted_data, validation_result)\n",
        "\n",
        "    # Small delay to avoid rate limiting\n",
        "    time.sleep(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDwzYmASY3vV",
        "outputId": "7950086e-56fd-45b2-c83c-b2c3c4437997"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 TESTING INFORMATION EXTRACTION ON SAMPLE CONVERSATIONS\n",
            "\n",
            "\n",
            "================================================================================\n",
            "📋 TEST CASE 1\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "📝 CONVERSATION:\n",
            "------------------------------------------------------------\n",
            "\n",
            "    Customer: Hi, I'd like to create an account.\n",
            "    Support: Sure! I'd be happy to help you create an account. May I have your full name?\n",
            "    Customer: Yes, my name is John Michael Smith.\n",
            "    Support: Thank you, Mr. Smith. And what email address would you like to use?\n",
            "    Customer: Please use john.smith@email.com\n",
            "    Support: Perfect. Can I also get a phone number for account security?\n",
            "    Customer: Sure, it's +1-555-123-4567\n",
            "    Support: Great! And where are you located?\n",
            "    Customer: I'm in San Francisco, California, United States.\n",
            "    Support: Excellent. One last thing - may I ask your age for our demographics?\n",
            "    Customer: I'm 28 years old.\n",
            "    Support: Thank you! Your account has been created successfully.\n",
            "    \n",
            "\n",
            "🔍 EXTRACTED INFORMATION:\n",
            "------------------------------------------------------------\n",
            "{\n",
            "  \"age\": 28,\n",
            "  \"email\": \"john.smith@email.com\",\n",
            "  \"location\": {\n",
            "    \"city\": \"San Francisco\",\n",
            "    \"country\": \"United States\",\n",
            "    \"state\": \"California\"\n",
            "  },\n",
            "  \"name\": \"John Michael Smith\",\n",
            "  \"phone\": \"+1-555-123-4567\"\n",
            "}\n",
            "\n",
            "✅ VALIDATION RESULT:\n",
            "------------------------------------------------------------\n",
            "✓ Data is valid according to schema\n",
            "============================================================\n",
            "\n",
            "================================================================================\n",
            "📋 TEST CASE 2\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "📝 CONVERSATION:\n",
            "------------------------------------------------------------\n",
            "\n",
            "    User: Hello, I'm interested in your services.\n",
            "    Agent: Welcome! I'd be glad to help. What's your name?\n",
            "    User: I'm Sarah Johnson.\n",
            "    Agent: Nice to meet you, Sarah. How can I reach you?\n",
            "    User: You can email me at sarah.j@gmail.com\n",
            "    Agent: Thanks! Where are you based?\n",
            "    User: I'm in Toronto, Canada.\n",
            "    Agent: Great! Do you mind sharing your age group for our records?\n",
            "    User: I'd prefer not to share that information.\n",
            "    Agent: No problem at all! Let me show you our services.\n",
            "    \n",
            "\n",
            "🔍 EXTRACTED INFORMATION:\n",
            "------------------------------------------------------------\n",
            "{\n",
            "  \"email\": \"sarah.j@gmail.com\",\n",
            "  \"location\": {\n",
            "    \"city\": \"Toronto\",\n",
            "    \"country\": \"Canada\"\n",
            "  },\n",
            "  \"name\": \"Sarah Johnson\"\n",
            "}\n",
            "\n",
            "✅ VALIDATION RESULT:\n",
            "------------------------------------------------------------\n",
            "✓ Data is valid according to schema\n",
            "============================================================\n",
            "\n",
            "================================================================================\n",
            "📋 TEST CASE 3\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "📝 CONVERSATION:\n",
            "------------------------------------------------------------\n",
            "\n",
            "    Customer: Hi there! I just moved to Austin, Texas from New York.\n",
            "    Sales: Welcome to Austin! How are you finding it so far?\n",
            "    Customer: It's great! Much warmer than NYC. By the way, I'm David Lee.\n",
            "    Sales: Nice to meet you, David! What brings you to our store today?\n",
            "    Customer: I need to update my contact information. I'm 35 now and figured it's time to get organized.\n",
            "    Sales: Absolutely! What's the best way to reach you?\n",
            "    Customer: My phone is 512-789-0123. That's the best way.\n",
            "    Sales: Got it. Do you have an email as well?\n",
            "    Customer: Oh yes, david.lee.35@hotmail.com - I know, showing my age with Hotmail!\n",
            "    Sales: Haha, no judgment here! Let me update your information.\n",
            "    Customer: Actually, I should mention I'm originally from South Korea, moved to the US five years ago.\n",
            "    Sales: Thanks for sharing! Is Austin, Texas your permanent address now?\n",
            "    Customer: Yes, Austin, Texas, USA is home now!\n",
            "    \n",
            "\n",
            "🔍 EXTRACTED INFORMATION:\n",
            "------------------------------------------------------------\n",
            "{\n",
            "  \"age\": 35,\n",
            "  \"email\": \"david.lee.35@hotmail.com\",\n",
            "  \"location\": {\n",
            "    \"city\": \"Austin\",\n",
            "    \"country\": \"USA\",\n",
            "    \"state\": \"Texas\"\n",
            "  },\n",
            "  \"name\": \"David Lee\",\n",
            "  \"phone\": \"512-789-0123\"\n",
            "}\n",
            "\n",
            "✅ VALIDATION RESULT:\n",
            "------------------------------------------------------------\n",
            "✓ Data is valid according to schema\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Project Summary and Results\n",
        "\n",
        "### Task 1: Conversation Management ✅\n",
        "Successfully implemented:\n",
        "- **Truncation by turns**: Limit conversation history by number of messages\n",
        "- **Truncation by character length**: Control memory usage with character limits\n",
        "- **Combined truncation**: Apply both turn and character limits simultaneously\n",
        "- **Periodic summarization**: Automatically summarize every k conversations\n",
        "- **Summary consolidation**: Merge new summaries with existing ones\n",
        "\n",
        "### Task 2: Information Extraction ✅\n",
        "Successfully implemented:\n",
        "- **JSON Schema definition**: Structured schema for 5 information fields\n",
        "- **Function calling**: Used Groq's OpenAI-compatible function calling\n",
        "- **Robust extraction**: Handled complete, partial, and scattered information\n",
        "- **Schema validation**: Validated all extracted data against defined schema\n",
        "\n",
        "### Key Features\n",
        "1. **No frameworks used** - Only standard Python libraries and OpenAI client\n",
        "2. **Clean, documented code** - Every function and class is well-documented\n",
        "3. **Comprehensive demonstrations** - Multiple test cases showing various scenarios\n",
        "4. **Error handling** - Graceful error handling throughout the implementation\n",
        "\n",
        "### Technical Implementation\n",
        "- **API**: Groq API with OpenAI SDK compatibility\n",
        "- **Model**: llama-3.1-8b-instant\n",
        "- **Languages**: Python 3.x\n",
        "- **Environment**: Google Colab\n",
        "\n",
        "---\n",
        "\n",
        "This project demonstrates proficiency in:\n",
        "- API integration and management\n",
        "- Conversation history handling\n",
        "- Natural language processing\n",
        "- Structured data extraction\n",
        "- Clean code practices\n"
      ],
      "metadata": {
        "id": "185s2TnGZZtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final confirmation\n",
        "print(\"🎉 PROJECT COMPLETED SUCCESSFULLY!\")\n",
        "print(\"\\n📊 Final Statistics:\")\n",
        "print(f\"- Task 1: Conversation Management with {len(manager2.all_summaries)} successful summarizations\")\n",
        "print(f\"- Task 2: Information Extraction with {len(sample_conversations)} test cases validated\")\n",
        "print(\"\\n✅ All requirements met:\")\n",
        "print(\"- No frameworks used\")\n",
        "print(\"- Groq API with OpenAI SDK\")\n",
        "print(\"- Clean, documented code\")\n",
        "print(\"- Comprehensive demonstrations\")\n",
        "print(\"- API key included for testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsy2lFskZC0r",
        "outputId": "cc779f55-831d-44a4-8481-8c969a3c4bac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 PROJECT COMPLETED SUCCESSFULLY!\n",
            "\n",
            "📊 Final Statistics:\n",
            "- Task 1: Conversation Management with 2 successful summarizations\n",
            "- Task 2: Information Extraction with 3 test cases validated\n",
            "\n",
            "✅ All requirements met:\n",
            "- No frameworks used\n",
            "- Groq API with OpenAI SDK\n",
            "- Clean, documented code\n",
            "- Comprehensive demonstrations\n",
            "- API key included for testing\n"
          ]
        }
      ]
    }
  ]
}